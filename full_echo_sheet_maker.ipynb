{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4077c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the lines below to use this sheet to turn DOE designs or experimental designs into ECHO Sheets. \n",
    "#This will be the \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Add location of the excel sheet that will be used: \n",
    "experiment_sheet = '11_14_24_pyrogallol_melanin.xlsx'\n",
    "\n",
    "#Choose what kind of plate you are using, change number to 25 if a 384 or 49 if a 1536 well plate:\n",
    "plate_type = 49\n",
    "\n",
    "#dispensing volumes used to create the echo sheet\n",
    "experiment_grid = 'experiment_grid'\n",
    "\n",
    "#add location of the volume matrix for the plate, this is a sheet called dispensing volume, and the condition sheet for each dispensing well. \n",
    "dispensing = 'dispensing_volume'\n",
    "conditions = 'dispensing_conditions'\n",
    "\n",
    "#location of the data that will be headered and used for downstream analysis: \n",
    "plate_reader_data = 'plate_reader_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f82ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dispensing_volume' has been added.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the Excel sheet \"experiment grid\"\n",
    "file_path = experiment_sheet  # Update this path to your Excel file\n",
    "df = pd.read_excel(file_path, sheet_name='experiment_grid')\n",
    "\n",
    "# Set the threshold (e.g., 5000)\n",
    "threshold = 23000\n",
    "\n",
    "# Initialize the new DataFrame with the Run column\n",
    "new_df = pd.DataFrame(df['Run'])\n",
    "\n",
    "# Function to add new columns dynamically\n",
    "def add_new_column(new_df, col, suffix):\n",
    "    new_col = f\"{col}_{suffix}\"\n",
    "    new_df[new_col] = 0\n",
    "    return new_col\n",
    "\n",
    "# Split the columns and move values based on the threshold\n",
    "for col in df.columns:\n",
    "    if col != 'Run':\n",
    "        suffix = 1\n",
    "        new_col = add_new_column(new_df, col, suffix)\n",
    "        total = 0\n",
    "        for i, value in enumerate(df[col]):\n",
    "            if pd.isna(value):  # Check for NaN (blanks) and treat them as zeros\n",
    "                value = 0\n",
    "            if total + value > threshold:\n",
    "                suffix += 1\n",
    "                new_col = add_new_column(new_df, col, suffix)\n",
    "                total = 0\n",
    "            new_df.at[i, new_col] = value\n",
    "            total += value\n",
    "\n",
    "# Write the new DataFrame to a new sheet in the same Excel file\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace') as writer:\n",
    "    new_df.to_excel(writer, sheet_name='dispensing_volume', index=False)\n",
    "\n",
    "print(\"'dispensing_volume' has been added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b39351-9b4c-4d2d-90e9-a43e2c267e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting well (e.g., B1):  A1\n",
      "Enter Sample IDs and their Source Plate Types (format: ID1:Type1, ID2:Type2,...), or press Enter to skip:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Sample ID Source Well Source Plate Type\n",
      "0   Laccase A. niger(0.2mg/mL)_1          A1     384PP_Plus_AQ\n",
      "1     Laccase A. niger(2mg/mL)_1          A2     384PP_Plus_AQ\n",
      "2      1_3 dihydroxynapthalene_1          A3     384PP_Plus_AQ\n",
      "3      2_7 dihydroxynapthalene_1          A4     384PP_Plus_AQ\n",
      "4      1_4 dihydroxynapthalene_1          A5     384PP_Plus_AQ\n",
      "5                  Pyrogallol _1          A6     384PP_Plus_AQ\n",
      "6                  Pyrogallol _2          A7     384PP_Plus_AQ\n",
      "7      1_5 dihydroxynapthalene_1          A8     384PP_Plus_AQ\n",
      "8                     Catechol_1          A9     384PP_Plus_AQ\n",
      "9      1_6 dihydroxynapthalene_1         A10     384PP_Plus_AQ\n",
      "10  3_4-dihydroxybenzoic acid _1         A11     384PP_Plus_AQ\n",
      "11     1_7 dihydroxynapthalene_1         A12     384PP_Plus_AQ\n",
      "12      4-hydroxybenzoic acid _1         A13     384PP_Plus_AQ\n",
      "13     1_8 dihydroxynapthalene_1         A14     384PP_Plus_AQ\n",
      "14      3-hydroxybenzoic acid _1         A15     384PP_Plus_AQ\n",
      "15     2_3 dihydroxynapthalene_1         A16     384PP_Plus_AQ\n",
      "16                   Guaiacol _1         A17     384PP_Plus_AQ\n",
      "17     2_6 dihydroxynapthalene_1         A18     384PP_Plus_AQ\n",
      "18                  Resorcinol_1         A19     384PP_Plus_AQ\n",
      "19         Benzene 1_2_4 Triol_1         A20     384PP_Plus_AQ\n",
      "20                      Phenol_1         A21     384PP_Plus_AQ\n",
      "21                   1-napthol_1         A22     384PP_Plus_AQ\n",
      "22                   2-napthol_1         A23     384PP_Plus_AQ\n",
      "23                  Anthracene_1         A24     384PP_Plus_AQ\n",
      "24               2-Aminophenol_1          B1     384PP_Plus_AQ\n",
      "The new sheet 'dispensing_conditions' has been added to the Excel file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to generate 384-well pattern in row-major order\n",
    "def generate_384_well_pattern(start_well):\n",
    "    rows = 'ABCDEFGHIJKLMNOP'\n",
    "    cols = range(1, 25)\n",
    "    well_pattern = [f\"{row}{col}\" for row in rows for col in cols]\n",
    "    \n",
    "    if start_well not in well_pattern:\n",
    "        raise ValueError(\"Invalid starting well position.\")\n",
    "    \n",
    "    start_index = well_pattern.index(start_well)\n",
    "    return well_pattern[start_index:] + well_pattern[:start_index]\n",
    "\n",
    "# Function to get the Source Plate Type from the user\n",
    "def get_source_plate_types(sample_ids, default_type, available_types):\n",
    "    plate_types = [default_type] * len(sample_ids)\n",
    "    exceptions = input(\"Enter Sample IDs and their Source Plate Types (format: ID1:Type1, ID2:Type2,...), or press Enter to skip: \")\n",
    "    \n",
    "    if exceptions:\n",
    "        exception_list = exceptions.split(',')\n",
    "        for exception in exception_list:\n",
    "            sample_id, plate_type = exception.split(':')\n",
    "            sample_id = sample_id.strip()\n",
    "            plate_type = plate_type.strip()\n",
    "            \n",
    "            if sample_id in sample_ids and plate_type in available_types:\n",
    "                index = sample_ids.index(sample_id)\n",
    "                plate_types[index] = plate_type\n",
    "            else:\n",
    "                print(f\"Invalid entry: {sample_id} or {plate_type} is not recognized.\")\n",
    "    \n",
    "    return plate_types\n",
    "\n",
    "# Read the data from the Excel sheet \"dispensing_volume\"\n",
    "file_path = experiment_sheet  # Update this path to your Excel file\n",
    "df_dispensing_volume = pd.read_excel(file_path, sheet_name='dispensing_volume')\n",
    "\n",
    "# Extract the headers excluding the first one and transpose them into a new DataFrame\n",
    "dispensing_conditions = pd.DataFrame(df_dispensing_volume.columns[1:], columns=['Sample ID'])\n",
    "\n",
    "# Ask user for the starting well\n",
    "start_well = input(\"Enter the starting well (e.g., B1): \")\n",
    "\n",
    "# Generate the 384-well pattern starting from the specified well\n",
    "well_pattern = generate_384_well_pattern(start_well)\n",
    "\n",
    "# Fill the 'Source Well' column with the generated pattern\n",
    "dispensing_conditions['Source Well'] = well_pattern[:len(dispensing_conditions)]\n",
    "\n",
    "# Define available Source Plate Types\n",
    "available_types = [\n",
    "    '384PP_Plus_AQ', '384PP_AQ_BP', '384PP_AQ_SP', '384PP_AQ_SP_High',\n",
    "    '384PP_Plus_AQ_BP', '384PP_Plus_AQ_GP', '384PP_Plus_AQ_GPSA',\n",
    "    '384PP_Plus_AQ_GPSB', '384PP_Plus_AQ_SP'\n",
    "]\n",
    "\n",
    "# Get the Source Plate Type from the user\n",
    "default_type = '384PP_Plus_AQ'\n",
    "sample_ids = dispensing_conditions['Sample ID'].tolist()\n",
    "source_plate_types = get_source_plate_types(sample_ids, default_type, available_types)\n",
    "\n",
    "# Fill the 'Source Plate Type' column with the appropriate values\n",
    "dispensing_conditions['Source Plate Type'] = source_plate_types\n",
    "\n",
    "# Print the resulting DataFrame for testing\n",
    "print(dispensing_conditions)\n",
    "\n",
    "# Write the new DataFrame to a new sheet in the same Excel file\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='replace') as writer:\n",
    "    dispensing_conditions.to_excel(writer, sheet_name='dispensing_conditions', index=False)\n",
    "\n",
    "print(\"The new sheet 'dispensing_conditions' has been added to the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606d982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the starting well (e.g., A1):  A1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Source Plate Source Plate Type Source Well                     Sample ID  \\\n",
      "0       Source[1]  384PP_Plus_AQ_BP          F1  Laccase A. niger(0.2mg/mL)_1   \n",
      "1       Source[1]  384PP_Plus_AQ_BP          F2    Laccase A. niger(2mg/mL)_1   \n",
      "2       Source[1]  384PP_Plus_AQ_BP          F3     1_3 dihydroxynapthalene_1   \n",
      "3       Source[1]  384PP_Plus_AQ_BP          F4     2_7 dihydroxynapthalene_1   \n",
      "4       Source[1]  384PP_Plus_AQ_BP          F5     1_4 dihydroxynapthalene_1   \n",
      "...           ...               ...         ...                           ...   \n",
      "2195    Source[1]  384PP_Plus_AQ_BP         F21                      Phenol_1   \n",
      "2196    Source[1]  384PP_Plus_AQ_BP         F22                   1-napthol_1   \n",
      "2197    Source[1]  384PP_Plus_AQ_BP         F23                   2-napthol_1   \n",
      "2198    Source[1]  384PP_Plus_AQ_BP         F24                  Anthracene_1   \n",
      "2199    Source[1]  384PP_Plus_AQ_BP          G1               2-Aminophenol_1   \n",
      "\n",
      "     Destination Plate Name Destination Well  Transfer Volume  \\\n",
      "0                384PP_Dest               A1                0   \n",
      "1                384PP_Dest               A1                0   \n",
      "2                384PP_Dest               A1              475   \n",
      "3                384PP_Dest               A1                0   \n",
      "4                384PP_Dest               A1                0   \n",
      "...                     ...              ...              ...   \n",
      "2195             384PP_Dest              B17                0   \n",
      "2196             384PP_Dest              B17                0   \n",
      "2197             384PP_Dest              B17                0   \n",
      "2198             384PP_Dest              B17                0   \n",
      "2199             384PP_Dest              B17              725   \n",
      "\n",
      "      Destination Well X Offset  Destination Well Y Offset  \n",
      "0                             0                          0  \n",
      "1                             0                          0  \n",
      "2                             0                          0  \n",
      "3                             0                          0  \n",
      "4                             0                          0  \n",
      "...                         ...                        ...  \n",
      "2195                          0                          0  \n",
      "2196                          0                          0  \n",
      "2197                          0                          0  \n",
      "2198                          0                          0  \n",
      "2199                          0                          0  \n",
      "\n",
      "[2200 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def well_to_index(start_well):\n",
    "    # Split the input into row (letter) and column (number) parts\n",
    "    row = start_well[:-1].upper()  # Row part (e.g., \"A\" from \"A1\")\n",
    "    col = int(start_well[-1:])  # Column part (e.g., \"1\" from \"A1\")\n",
    "\n",
    "    # List of rows from A to Z and double letters for larger plates\n",
    "    rows = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ') + [chr(i) + chr(i) for i in range(65, 91)]\n",
    "    \n",
    "    # Calculate the index based on the row and column\n",
    "    row_index = rows.index(row)\n",
    "    index = row_index * plate_type + (col - 1)  # Adjust to 0-based index\n",
    "    return index\n",
    "\n",
    "def run_to_well(run, start_well='A1'):\n",
    "    # List of rows from A to Z and double letters for larger plates\n",
    "    rows = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ') + [chr(i) + chr(i) for i in range(65, 91)]\n",
    "    # List of columns based on the plate type\n",
    "    cols = list(range(1, plate_type + 1))\n",
    "    # Creating the well labels\n",
    "    wells = [f'{r}{c}' for r in rows for c in cols]\n",
    "    \n",
    "    # Get the start well index\n",
    "    start_index = well_to_index(start_well)\n",
    "    \n",
    "    # Adjust the run by the start_well index\n",
    "    return wells[run + start_index - 1]  # Adjusted for 0-based indexing\n",
    "\n",
    "# Ask the user for the starting well\n",
    "start_well = input(\"Please enter the starting well (e.g., A1): \")\n",
    "\n",
    "# Read the first sheet of the Excel file into a DataFrame\n",
    "df = pd.read_excel(experiment_sheet, sheet_name=dispensing)\n",
    "\n",
    "# Transpose the DataFrame so that the components are columns\n",
    "df = df.transpose()\n",
    "\n",
    "# Reset the index so that the components become a column\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to reflect the new structure\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "\n",
    "# Rename the 'Run' column to 'Sample ID'\n",
    "df.rename(columns={'Run': 'Sample ID'}, inplace=True)\n",
    "\n",
    "# Read the second sheet (with the 'Source Well', 'Source Plate Type', \n",
    "# and offsets for each well) into a DataFrame\n",
    "df_source_data = pd.read_excel(experiment_sheet, sheet_name=conditions)\n",
    "\n",
    "# Melt the DataFrame from wide format to long format\n",
    "df_melted = df.melt(id_vars='Sample ID', var_name='Run', value_name='Transfer Volume')\n",
    "\n",
    "# Convert 'Run' to numeric\n",
    "df_melted['Run'] = pd.to_numeric(df_melted['Run'])\n",
    "\n",
    "# Apply run_to_well function to 'Run' column to get 'Destination Well', starting from the specified well\n",
    "df_melted['Destination Well'] = df_melted['Run'].apply(lambda x: run_to_well(x, start_well=start_well))\n",
    "\n",
    "# Merge df_melted with df_source_data to get corresponding Source Well, Source Plate Type, and X/Y Offsets for each Sample ID\n",
    "df_melted = pd.merge(df_melted, df_source_data, on='Sample ID', how='left')\n",
    "\n",
    "# Add the additional columns\n",
    "df_melted['Source Plate'] = 'Source[1]'\n",
    "df_melted['Destination Plate Name'] = '384PP_Dest'\n",
    "\n",
    "# Ensure the DataFrame includes 'Destination Well X Offset' and 'Destination Well Y Offset' from the source data\n",
    "if 'Destination Well X Offset' not in df_melted.columns:\n",
    "    df_melted['Destination Well X Offset'] = 0  # default if not provided\n",
    "if 'Destination Well Y Offset' not in df_melted.columns:\n",
    "    df_melted['Destination Well Y Offset'] = 0  # default if not provided\n",
    "\n",
    "# Reorder the columns to match the desired output\n",
    "df_melted = df_melted[['Source Plate', 'Source Plate Type', 'Source Well', 'Sample ID', \n",
    "                       'Destination Plate Name', 'Destination Well', 'Transfer Volume',\n",
    "                       'Destination Well X Offset', 'Destination Well Y Offset']]\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = experiment_sheet\n",
    "\n",
    "# Specify the name of the new sheet\n",
    "new_sheet_name = 'ECHO_SHEET'\n",
    "\n",
    "# Write the DataFrame to a new sheet in the same Excel file\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl', mode='a') as writer:\n",
    "    df_melted.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(df_melted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47f1868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new sheet 'plate_reader_data' has been added to the Excel file.\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "\n",
    "# Define the path to your Excel file\n",
    "file_path = experiment_sheet  # Update this path to your Excel file\n",
    "\n",
    "# Open the workbook and select the sheet\n",
    "wb = openpyxl.load_workbook(file_path)\n",
    "experiment_grid = 'experiment_grid'\n",
    "plate_reader_data = 'plate_reader_data'\n",
    "\n",
    "# Read reagents from the first row, skipping the first cell\n",
    "sheet = wb[experiment_grid]\n",
    "reagents = [cell.value for cell in sheet[1]][1:]\n",
    "\n",
    "# Read data from the sheet\n",
    "data = {}\n",
    "for row in sheet.iter_rows(min_row=2, values_only=True):  # Skip the first row (headers)\n",
    "    test = row[0]\n",
    "    values = list(row[1:])  # Skip the first column (test names)\n",
    "    data[test] = values\n",
    "\n",
    "# Create headers\n",
    "headers = {}\n",
    "for test, values in data.items():\n",
    "    headers[test] = []\n",
    "    for i, value in enumerate(values):\n",
    "        if value != 0 and value is not None:  # Check for non-zero and non-None values\n",
    "            headers[test].append(f\"{reagents[i]}:{value}\")\n",
    "\n",
    "# Convert list of headers to a single string for each test\n",
    "output = []\n",
    "for test, values in headers.items():\n",
    "    if values:  # Only add to output if there are headers\n",
    "        headers_string = ', '.join(values)\n",
    "    else:\n",
    "        headers_string = 'None'  # Add 'None' if there are no headers\n",
    "    output.append(headers_string)  # Removed test name from output\n",
    "\n",
    "# Create or open the 'plate_reader_data' sheet\n",
    "if plate_reader_data in wb.sheetnames:\n",
    "    sheet = wb[plate_reader_data]\n",
    "else:\n",
    "    sheet = wb.create_sheet(title=plate_reader_data)\n",
    "\n",
    "# Clear existing content in the 'plate_reader_data' sheet\n",
    "for row in sheet.iter_rows():\n",
    "    for cell in row:\n",
    "        cell.value = None\n",
    "\n",
    "# Write output to the top row of the 'plate_reader_data' sheet in an Excel file\n",
    "for i, header in enumerate(output, start=2):  # Start from the second column to avoid the time column\n",
    "    sheet.cell(row=1, column=i, value=header)\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_path)\n",
    "\n",
    "print(\"The new sheet 'plate_reader_data' has been added to the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the file path\n",
    "data = experiment_sheet\n",
    "sheet_name= 'plate_reader_data'\n",
    "\n",
    "# Read the excel file and specify the sheet name\n",
    "df = pd.read_excel(data, sheet_name)\n",
    "\n",
    "# Convert the dataframe to a numpy array\n",
    "df = df.to_numpy()\n",
    "\n",
    "# Ignore the first column and use it as time\n",
    "time = df[:, 0]\n",
    "\n",
    "# Define a function to take the average or standard deviation of every x columns\n",
    "def agg_columns(df, x, agg_func):\n",
    "    # Create an empty list to store the results\n",
    "    results = []\n",
    "    # Loop through the columns in groups of x\n",
    "    for i in range(1, len(df[0]), x):\n",
    "        # Calculate the aggregation of the group and append it to the list\n",
    "        results.append(agg_func(df[:, i:i+x], axis=1))\n",
    "    # Return the list of results as a new dataframe\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# Set x and y to the desired values\n",
    "x = 4\n",
    "y = 24\n",
    "\n",
    "# Get the headers from the original dataframe\n",
    "headers = pd.read_excel(data, sheet_name).columns\n",
    "\n",
    "# Calculate number of rows and columns for subplots\n",
    "nrows = int(np.ceil(8))\n",
    "ncols = min(1, y)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(40, 100), dpi=300)\n",
    "axs = axs.flatten()  # to handle case when y < 4\n",
    "\n",
    "# Loop through the data by y columns\n",
    "for j in range(0, len(df[0]), y):\n",
    "    # Call the agg_columns function and get the averages and standard deviations dataframes for current y columns\n",
    "    averages = agg_columns(df[:, j:j+y], x, np.mean)\n",
    "    stds = agg_columns(df[:, j:j+y], x, np.std)\n",
    "\n",
    "    # Set the font family and size\n",
    "    plt.rc('font', family='Arial', size=24)\n",
    "\n",
    "    # Loop through the columns of the averages dataframe\n",
    "    for i in range(len(averages.columns)):\n",
    "        # Plot the column as a line against time with a color and marker\n",
    "        axs[j//y].plot(time, averages.iloc[:, i], label=str(headers[i*x+j+1]), color=\"C\"+str(i), marker=\"o\")\n",
    "        # Calculate the upper and lower bounds of the shadow\n",
    "        upper = averages.iloc[:, i] + stds.iloc[:, i]\n",
    "        lower = averages.iloc[:, i] - stds.iloc[:, i]\n",
    "        # Fill the area between the bounds with a transparent color\n",
    "        axs[j//y].fill_between(time, upper, lower, color=\"C\"+str(i), alpha=0.2)\n",
    "\n",
    "    # Add labels and title with descriptive text\n",
    "    axs[j//y].set_xlabel(\"Time (Mins)\")\n",
    "    axs[j//y].set_ylabel(\"RFU\")\n",
    "    axs[j//y].set_title(\"\")\n",
    "    \n",
    "    #set the Y-Lim\n",
    "    axs[j//y].set_ylim([0, 12000])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Add a legend with a location and frame\n",
    "    axs[j//y].legend(loc=\"upper left\", frameon=True, fontsize=30)\n",
    "    \n",
    "\n",
    "    # Add grid lines for readability\n",
    "    #axs[j//y].grid(True, linestyle='--', color='gray', linewidth=0.5)\n",
    "\n",
    "    # Set axis spines to be invisible except bottom one\n",
    "    axs[j//y].spines['top'].set_visible(False)\n",
    "    axs[j//y].spines['right'].set_visible(False)\n",
    "    \n",
    "# Save each figure as a high-quality PNG image with unique name based on j value\n",
    "plt.savefig(\"plot.png\", format=\"png\", dpi=300)\n",
    "\n",
    "# Show each plot separately on screen \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33935ad5-b87a-4e3e-b264-c31f46da502d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
